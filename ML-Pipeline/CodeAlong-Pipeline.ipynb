{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77aac50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6d4ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74cc450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Ad Topic Line\", \"City\", \"Country\", \"Timestamp\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00524c0",
   "metadata": {},
   "source": [
    "# SlowerVersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73b4ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating Features and Targets\n",
    "target_var = \"Clicked on Ad\"\n",
    "y = df[target_var]\n",
    "X = df.drop(target_var, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94b904f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "233919e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d9b4087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a149ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       120\n",
      "           1       0.98      0.95      0.96       130\n",
      "\n",
      "    accuracy                           0.96       250\n",
      "   macro avg       0.96      0.96      0.96       250\n",
      "weighted avg       0.96      0.96      0.96       250\n",
      "\n",
      "Test set accuracy: 0.964\n"
     ]
    }
   ],
   "source": [
    "#Making the Predictions and Evaluating the Model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test set accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c6b92a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.9739792165832041\n",
      "Best parameters: {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "# Performing Grid Search for Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, scoring=\"f1\", cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b6daca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       120\n",
      "           1       0.98      0.95      0.96       130\n",
      "\n",
      "    accuracy                           0.96       250\n",
      "   macro avg       0.96      0.96      0.96       250\n",
      "weighted avg       0.96      0.96      0.96       250\n",
      "\n",
      "Test set accuracy with best model: 0.964\n"
     ]
    }
   ],
   "source": [
    "# Using the Best Model from Grid Search\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Classification report for the best model\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "# Accuracy score for the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"Test set accuracy with best model: {accuracy_best}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762ac024",
   "metadata": {},
   "source": [
    "# Using Pipelines for Efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f742fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Juxtapose this with Pipelines\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eed22461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9739792165832041: {'logisticregression__C': 1}\n"
     ]
    }
   ],
   "source": [
    "#Pipeline\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "param_grid = [\n",
    "    {\"logisticregression__C\": [0.001, 0.01, 0.1, 1, 10]}\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid, scoring=\"f1\")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"{clf.best_score_}: {clf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3d18cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying Another Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beea4390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9701539044251379: {'gradientboostingclassifier__learning_rate': 0.1, 'gradientboostingclassifier__max_depth': 3, 'gradientboostingclassifier__n_estimators': 100, 'gradientboostingclassifier__subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "#Xgboost\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), GradientBoostingClassifier())\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'gradientboostingclassifier__n_estimators': [50, 100],       # Number of boosting stages\n",
    "    'gradientboostingclassifier__learning_rate': [0.1, 0.2],     # Learning rate shrinks the contribution of each tree\n",
    "    'gradientboostingclassifier__max_depth': [3, 4],             # Maximum depth of the individual regression estimators\n",
    "    'gradientboostingclassifier__subsample': [0.8, 1.0]          # Fraction of samples used for fitting the individual base learners\n",
    "}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid, scoring=\"f1\")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"{clf.best_score_}: {clf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70927ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.932"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = clf.best_estimator_\n",
    "best_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa5687f",
   "metadata": {},
   "source": [
    "# Advantages of using a pipeline\n",
    "\n",
    "Consistency: The same preprocessing steps (e.g., scaling) are automatically applied to both the training and test data.\n",
    "\n",
    "you might accidentally forget to apply scaling to your test data after scaling your training data, leading to poor model performance.\n",
    "\n",
    "With a pipeline, you define the scaling step once, and it’s guaranteed to be applied consistently to all data.\n",
    "\n",
    "Efficiency: Reduces repetitive code and potential for errors by automating preprocessing.\n",
    "\n",
    "Using GridSearchCV with pipelines is straightforward, as the entire pipeline is optimized, ensuring that hyperparameter tuning takes all steps into account.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5be790",
   "metadata": {},
   "source": [
    "# Data Leakage \n",
    "\n",
    "Preventing Data Leakage\n",
    "Detailed Explanation:\n",
    "\n",
    "Data leakage can significantly inflate the model's performance metrics, giving an unrealistic estimate of its real-world performance. It happens when the information from the test set is inadvertently used to train the model.\n",
    "Pipelines prevent data leakage by ensuring that all preprocessing steps are applied separately to the training and test sets within the cross-validation loop, not before the split.\n",
    "Example: Data Leakage without Pipelines\n",
    "Without Pipelines:\n",
    "\n",
    "Scaling data before splitting it into training and test sets can lead to data leakage. The scaler learns from the entire dataset, including the test set, which should not influence the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e108b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
